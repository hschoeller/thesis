% !TeX root = ../main.tex
% =================================================
% Chapter 5: Lagrangian Coherence in Atmospheric Blocking
% =================================================

\chapter{Lagrangian Coherence in Atmospheric Blocking} % LaTeX chapter title
\label{chap:coherence}

The chapter is organized as follows. 
\Cref{sec:the} introduces the mathematical foundation relevant to the methods employed. 
\Cref{sec:imp} covers details about the implementation of our algorithm as well as the data used. 
We show results from the application of the algorithm to test cases in \Cref{sec:exc} 
to both elucidate the concepts and methods introduced before 
and investigate the problems and questions posed above. 
Finally, \Cref{sec:con} summarizes the findings.

\section{Theory}
\label{sec:the}

To extract coherent sets from Lagrangian trajectory data, we employ the method proposed by \textcite{banischUnderstandingGeometryTransport2017}. 
It uses local distances between data points to construct a diffusion operator that is used to estimate coherent sets by performing spectral clustering.
In the following, we give a brief introduction into coherent sets and diffusion maps. 
Our aim is to provide a good intuitive understanding.
For a formal and mathematically rigorous introduction of coherent sets using a transfer-operator based framework, we refer to \textcite{banischUnderstandingGeometryTransport2017} and \textcite{froylandAnalyticFrameworkIdentifying2013}. A thorough introduction to diffusion maps is given by \textcite{coifmanDiffusionMaps2006}.

\subsection{Coherent sets}
\label{sec:cs}

Informally put, coherent sets are time-dependent regions in space that remain largely intact as the system evolves. They exhibit a ``natural'' separation from their surrounding % complement
in the sense that flow across the boundary is small and geometric integrity is kept to a large degree. We characterize the geometric integrity of coherent sets by their robustness with respect to the addition of small noise. We first introduce the heuristics of coherent sets in an abstract setting before proceeding to the computation of coherent sets from trajectory data. 

Consider the evolution of points over a finite number of time steps in a non-autonomous dynamical system. Let $\mathbb{X}_t \subset \mathbb{R}^n$ be bounded sets which denote the domain of the dynamical system at each point in time. Here, $t$ ranges over the integers from $0$ to~$T$. A non-autonomous dynamical system in discrete time over these time-evolving domains is given by a sequence of bijective maps $\Phi_{t+1, t}: \mathbb{X}_t \to \mathbb{X}_{t+1}$, where $0 \leq t \leq T-1$. Before characterizing coherent sets of the dynamical system over the entire time frame from $0$ to $T$, we study sets that are coherent under a single step. %map. 

Consider a bijective map $\Phi:\mathbb{X} \rightarrow \mathbb{Y}$, with bounded domains $\mathbb{X}, \mathbb{Y} \subset \mathbb{R}^n$. We say that a set $\mathbb{A}\subset \mathbb{X}$ is coherent under $\Phi$ if the relation $(\Phi^{-1}\circ\Phi)(\mathbb{A}) = \mathbb{A}$ is robust under the addition of small noise both at initial and final time. As a consequence, we require that the sets $\mathbb{A}$ and $\Phi (\mathbb{A})$ are not too filamented, i.e.~that they possess high geometric integrity.
Let $ \mathcal{D}_\epsilon$ be a diffusion operator that applies an $\epsilon$-small random perturbation to any given point. The domain which $\mathcal{D}_\epsilon$ acts on will be clear from the context, i.e.~$\mathcal{D}_\epsilon: \mathbb{X} \to \mathbb{X}$ or $\mathcal{D}_\epsilon: \mathbb{Y} \to \mathbb{Y}$. A coherent set $\mathbb{A} \subset \mathbb{X}$ of the map $\Phi$ has to satisfy $\mathcal{D}_\epsilon \mathbb{A} \approx \mathbb{A}$ as well as $(\Phi^{-1} \circ \mathcal{D}_{\epsilon}\circ \Phi) (\mathbb{A}) \approx \mathbb{A}$. This heuristics is formulated more precisely in the language of transfer operators in \textcite{banischUnderstandingGeometryTransport2017}.

The above heuristics describe coherent sets of a single map $\Phi$. We return to the setting of a non-autonomous system over $T$ time steps given by the maps $\Phi_{t+1,t}$. A coherent set is a family of sets $(\mathbb{A}_t)_{0\leq t \leq T}$, where $\mathbb{A}_t\subset \mathbb{X}_t$ and $\Phi_{t+1, t} (\mathbb{A}_t) = \mathbb{A}_{t+1}$. Define the maps $\Phi_{t,0}=\Phi_{t, t-1}\circ \hdots \circ \Phi_{1,0}$. For $t=0$, the map $\Phi_{0,0}$ is simply the identity. A coherent set is completely characterized by $\mathbb{A}_0$, in the sense that $\mathbb{A}_t=\Phi_{t,0} (\mathbb{A}_0)$. We say that the family $(\mathbb{A}_t)_{0\leq t \leq T}$ is coherent if
\begin{equation}\label{eq:coherent_heuristic}
    (\Phi_{t,0}^{-1} \circ \mathcal{D}_\epsilon \circ \Phi_{t,0} )(\mathbb{A}_0) \approx \mathbb{A}_0,
\end{equation}
for all $t$ from $0$ to~$T$. We remark that this concept can be generalized to continuous time systems, e.g.~\textcite{matthesComputingCoherentSets2016}.

Note that we assumed that $\mathcal{D}_\epsilon$ maps from $\mathbb{X}_t$ into $\mathbb{X}_t$, i.e.~the random perturbation cannot map points outside of the domain~$\mathbb{X}_t$. This corresponds to e.g.~reflecting boundary conditions. For the purposes of our application, reflecting boundary conditions are physically not justifiable, since there are no physical boundaries for particles to be reflected at. Instead, we assume that $\mathcal{D}_\epsilon$ can transport points outside of~$\mathbb{X}_t$. Since we assume no information about the dynamics outside of $\mathbb{X}_t$, we consider points that are mapped outside of $\mathbb{X}_t$ as lost and hence unable of contributing to coherence. This corresponds to absorbing boundary conditions. We discuss how absorbing boundary conditions are implemented in the next subsection.

\subsection{Diffusion maps}
\label{sec:diffMaps}
In the following, we give a brief introduction to diffusion maps. A mathematically rigorous derivation can be found in \textcite{coifmanDiffusionMaps2006} and \textcite{ghojoghLaplacianBasedDimensionalityReduction2022}.

Assume the data of $m$ trajectories of a non-autonomous dynamics is provided in the form of data-points $\textbf{\textit{x}}_t^i\in \mathbb{R}^n$, where $1\leq i\leq m$ and $t$ ranges over the integers from $0$ to $T$. We assume that in each time frame the point cloud $X_t=\{x_t^i \: | \: 1\leq i \leq m\}$ approximates a bounded manifold $\mathbb{X}_t \subset \mathbb{R}^n$ and that the data-points are sample trajectories of a -- potentially unknown -- non-autonomous dynamics $\Phi_{t+1, t} :\mathbb{X}_t \to \mathbb{X}_{t+1}$, i.e.~$\Phi_{t,s} (x_s^i) = x_t^i$ for all $s\leq t$. Our goal is to characterize coherent sets of this dynamics, in particular to formalize the heuristic \cref{eq:coherent_heuristic} in the setting of discrete trajectory data. A coherent set consists of a certain subset of the point cloud, i.e.~$A_t := \{x_t^i\: | \: i\in \mathcal{I}\} \subset X_t$, where $\mathcal{I} \subset\{1, \hdots, m\}$ be a set of indices. In order to formalize the heuristic in \cref{eq:coherent_heuristic}, we introduce a discretization of the operator $\mathcal{D}_\epsilon : \mathbb{X}_t \to \mathbb{X}_t$ acting on the point cloud~$X_t$.

Since $X_t$ is a finite set of size $m$, we construct a transition probability matrix $\hat{\mathbf{P}}_{t, \epsilon} \in \mathbb{R}^{m\times m}$ that simulates diffusion on $X_t$ of strength $\epsilon$. The rest of this section is devoted to constructing the matrix $\hat{\mathbf{P}}_{t, \epsilon}$ for each $0\leq t \leq T$, as well as discussing the implementation of boundary conditions.
We remark that we do not need to approximate the dynamics $\Phi_{t+1,t}$ to use~\cref{eq:coherent_heuristic}, since we assume to have the data already in the form of trajectories.

Let $k_{\epsilon}$ be a symmetric diffusion kernel with scale parameter $\epsilon$. This kernel encodes the proximity of two data-points, i.e.~$k_\epsilon(x^i, x^j)$ is large if $x^i$ and $x^j$ are close and small if the points are far apart. In the following, we use the Gaussian kernel for an arbitrary metric $\text{dist}(\cdot,\cdot)$ on~$\mathbb{R}^n$,
\begin{equation} \label{eq:diffKernel}
    k_{\epsilon}(x^i, x^j) = \exp \left(-\frac{\text{dist}(x^i,x^j)^2}{\epsilon} \right).
\end{equation}
In general, it is natural to use the Euclidean distance $\text{dist}(x^i, x^j)=\|{x^i-x^j}\|$. However, for the application to atmospheric data, which is a non-isotropic setting, we are going to use an alternative distance aiming to establish isotropy with respect to turbulent diffusion, cf.~\cref{sec:dist}. For each time step $0\leq t \leq T$, we construct the similarity matrix $\mathbf{K}_{t,\epsilon} \in \mathbb{R}^{m\times m}$,
\begin{equation}\label{eq:similarity_matrix}
    \mathbf{K}_{t,\epsilon}(i,j) = k_\epsilon(x_t^i, x_t^j).
\end{equation}
Note that $\mathbf{K}_{t,\epsilon}$ is symmetric, all diagonal entries are $1$, while all off-diagonal entries are between $0$ and $1$. In practice, a cutoff radius is used to increase the sparsity of the matrix by setting entries $\mathbf{K}_{t, \epsilon}(i,j)$ that are below a specified threshold to $0$. Since the value $\mathbf{K}_{t, \epsilon}(i,j)$ decays monotonically in the distance between $x_t^i$ and $x_t^j$, we may equivalently choose a cutoff radius $r$ and set $\mathbf{K}_{t, \epsilon}(i,j)$ to $0$ if $\text{dist}(x_t^i, x_t^j) > r$. Here, we choose $r = 3\sqrt\epsilon$ which is an appropriate scaling for a Gaussian kernel $k_\epsilon$.

To account for differences in the density of the point cloud, we pre-normalize the similarity matrix:
\begin{equation}
    \left[\textbf{\textit{u}}_{t,\epsilon}\right]_{i} := \sum_{j=1}^m \left[\mathbf{K}_{t,\epsilon}\right]_{i,j} \, , \quad \left[\hat{\mathbf{K}}_{t,\epsilon}\right]_{i,j} := \frac{\left[\mathbf{K}_{t,\epsilon}\right]_{i,j}}{\left[\textbf{\textit{u}}_{t,\epsilon}\right]_{i}\left[\textbf{\textit{u}}_{t,\epsilon}\right]_{j}}.
\end{equation}
Finally, the diffusion matrix $\hat{\mathbf{P}}_{\epsilon}$ is obtained by row-normalization
\begin{equation}\label{eq:P}
    v_{t, \epsilon}(i) := \sum_{j=1}^m \hat{\mathbf{K}}_{t, \epsilon}(i,j), \quad \hat{\mathbf{P}}_{t, \epsilon}(i,j) := \frac{\hat{\mathbf{K}}_{t, \epsilon}(i,j)}{v_{t, \epsilon}(i)}.
\end{equation}
The matrix $\hat{\mathbf{P}}_{t, \epsilon}$ is non-negative and normalized such that it is row-stochastic (often called left stochastic), i.e.~the entries of each row sum to~$1$. Hence, $\hat{\mathbf{P}}_{t, \epsilon}$ can be understood as transition probabilities on the point cloud $\{x_t^i \: | \: 1\leq i \leq m\}$ that simulate a discretized diffusion on the point cloud $X_t$.
In the data-rich limit, $\hat{\mathbf{P}}_{t, \epsilon}$ is a self-adjoint operator, i.e.~a symmetric matrix.

Lastly, we address the implementation of boundary conditions. Since $\hat{\mathbf{P}}_{t,\epsilon}$, as constructed above, is a stochastic matrix, all points in $X_t$ remain in $X_t$, i.e.~there are reflecting boundary conditions. However, in the context of atmospheric flow of air masses, where $\mathbb{X}_t$ is a bounded, time-dependent region of the atmosphere, it is unnatural to assume turbulent diffusion would not act across the boundaries of $\mathbb{X}_t$. Since we assume no information about the dynamics outside of $\mathbb{X}_t$, we assume absorbing boundary conditions, i.e.~all points on the boundary of $X_t$ are removed. Hence, we need to determine a set of boundary points $\partial X_t \subset X_t$. Determining these point algorithmically is the content of \cref{sec:alpha_shapes}. Given a set of boundary points $\partial X_t$, we integrate absorbing boundary conditions into the transition matrix $\hat{\mathbf{P}}_{t,\epsilon}$ by removing the rows and columns corresponding to the boundary points. In order to keep the dimensions of the matrices compatible across different time steps, we implement this by setting the respective rows and columns to $0$ instead of removing them:
\begin{equation}
    \mathbf{P}_{t, \epsilon}(i, j) := \begin{cases}
        0, & x_t^i \in \partial X_t, \text{ or } x_t^j\in \partial X_t,\\ 
        \hat{\mathbf{P}}_{t, \epsilon}(i, j), \quad &\text{else}.
    \end{cases}
\end{equation}
By construction, $\mathbf{P}_{t, \epsilon}$ is a substochastic matrix. In summary, $\hat{\mathbf{P}}_{t, \epsilon}$ corresponds to a discretized diffusion matrix with reflecting boundary conditions while $\mathbf{P}_{t, \epsilon}$ corresponds to a discretized diffusion matrix with absorbing boundary conditions. For the purposes of our application, we will go forward using the substochastic matrix $\mathbf{P}_{t, \epsilon}$.

\subsection{Spectral clustering}
\label{sec:clust}
Having constructed the diffusion matrices $\mathbf{P}_{t,\epsilon}$, we describe how to compute coherent sets using a spectral clustering method. A coherent set $A_t$, where $0\leq t \leq T$, is given by $A_t=\{x_t^i \: | \: i\in \mathcal{I}\}$, where $\mathcal{I} \subset \{1, \hdots, m\}$ be a set of indices. In particular, we find $\Phi_{t,0} A_0 = A_t$. Hence, the heuristic in \cref{eq:coherent_heuristic}, using the diffusion matrix $\mathbf{P}_{t,\epsilon}$ introduced in the previous section, requires that indices $i\in \mathcal{I}$ have a high transition probability to $\mathcal{I}$, i.e.
\begin{equation*}
    \mathbf{P}_{t,\epsilon} (i, \mathcal{I}) := \sum_{j\in \mathcal{I}} \mathbf{P}_{t,\epsilon} (i, j) \approx 1,
\end{equation*}
for all $i\in \mathcal{I}$. This approximation should be as accurate as possible for all $0 \leq t \leq T$. We construct the averaged diffusion operator
\begin{equation}
    \label{eq:avg_dmap}
    \mathbf{Q}_\epsilon := \frac{1}{T+1} \sum_{t=0}^T \mathbf{P}_{t, \epsilon}.
\end{equation}
This averaged diffusion operator was introduced in \textcite{froylandDynamicIsoperimetryGeometry2015} and it was shown that coherent sets can be extracted from the dominant eigenvectors of~$\mathbf{Q}_\epsilon$.
\Cref{eq:avg_dmap} should be understood as a quantitative version of averaging the left-hand side of~\cref{eq:coherent_heuristic}. Thus, eigenvectors of $\mathbf{Q}_\epsilon$ for eigenvalues close to 1 represent functional representations of sets that satisfy~\cref{eq:coherent_heuristic} on average for~$0\leq t \leq T$.

To better understand how coherent sets are related to the eigenvectors of $\mathbf{Q}_\epsilon$, assume that there are $K$  idealized coherent sets $A_t^k$, for $1\leq k \leq K$, corresponding to the sets of indices~$\mathcal{I}^k$. These sets are idealized coherent sets in the sense that $\mathbf{Q}_\epsilon(i, \mathcal{I}^k)= 1$ for all $i\in \mathcal{I}^k$. Since $\mathbf{Q}_\epsilon$ is substochastic, this implies that $\mathbf{Q}_\epsilon$ has a block-diagonal structure with blocks indicated by the sets~$\mathcal{I}^k$. In particular, for each $1\leq k \leq K$, the matrix $\mathbf{Q}_\epsilon$ has an eigenvector with eigenvalue $1$ that is supported only on the set~$\mathcal{I}^k$. Hence, the $K$ coherent sets $\mathcal{I}^k$ can be extracted from eigenvectors to the $K$ largest eigenvalues. Additionally, there is an $(K+1)$-th set, which is the complement of the union of the $\mathcal{I}^k$ which we call the \emph{residual set}. The temporal evolution of $\mathbb{X}_t$ and, equivalently $X_t$, implies that $\partial X_t$ is time-dependent as well such that the residual set is not necessarily equal to~$\partial X_t$. The residual set, together with the coherent sets $\mathcal{I}^k$ form a partition of the set of all points~$\{1, \hdots, m\}$.

Returning to the general setting, we compute the eigenvalues of the matrix~$\mathbf{Q}_\epsilon$. In the data-rich limit, the matrix $\mathbf{Q}_\epsilon$ is symmetric and, thus, only has real eigenvalues. If complex eigenvalues occur numerically, we discard the imaginary part and only consider their real part. We order the eigenvalues from large to small. Since $\mathbf{Q}_\epsilon$ is substochastic, all eigenvalues lie between $0$ and~$1$. We say that there is a \emph{spectral gap} after the $K$-th eigenvalue, if the $(K+1)$-st eigenvalue is significantly smaller that the first $K$ eigenvalues. We call these first $K$ eigenvalues the \emph{dominant spectrum} and the corresponding eigenvectors the \emph{dominant eigenvectors}. After identifying a spectral gap, we perform a \texttt{k--means} clustering of the set of points $\{1, \hdots, m\}$ using the information of the dominant eigenvectors. Assuming that the dominant spectrum consists of $K$ eigenvalues, each point in $\{1, \hdots, m\}$ has $K$ characteristic values, namely the entries of the $K$ dominant eigenvectors. Using the \texttt{k--means} algorithm, we group the $m$ points into $K+1$ clusters $\mathcal{I}^k$, for $1 \leq k \leq K+1$. Like motivated by the idealized setting, $K$ of these sets correspond to coherent sets, while there is an additional $(K+1)$-th residual set. See~\cref{fig:coherent_sets_20160502} for an example of the spectrum of $\mathbf{Q}_\epsilon$ as well as the spectral clustering of the point cloud. The residual set is colored in gray.

\subsection{Quantifying coherence}
\label{sec:quantification}
To evaluate and interpret the computation of coherent sets in application, it is crucial to introduce a quantification of coherence of each of the clusters $\mathcal{I}_k$. Given a set of indices $\mathcal{I}_k \subset \{1, \hdots, m\}$, we restrict the averaged diffusion matrix $\mathbf{Q}_\epsilon$ to the indices $\mathcal{I}_k$ and compute the sum of its entries, divided by the size of $\mathcal{I}_k$. Heuristically, this corresponds to the probability that a point that is randomly chosen from $\mathcal{I}_k$ is mapped to another point in $\mathcal{I}_k$. As a notion of coherence we use the complementary probability, namely
\begin{equation} \label{eq:exitP}
    P_\text{exit}(\mathcal{I}_k) = 1 - \frac{1}{|\mathcal{I}_k|} \sum_{i,j\in \mathcal{I}_k} \mathbf{Q}_\epsilon(i,j).
\end{equation}
Note that since $\mathbf{Q}_\epsilon$ is substochastic, $ P_\text{exit}(\mathcal{I}_k)$ is between $0$ and $1$. A value close to $0$ corresponds to high coherence because the trajectories are tightly bundled with respect to the averaged diffusion matrix $\mathbf{Q}_\epsilon$. By construction, the exit whose probability is quantified can be to another coherent set, the residual set or out of the set of all trajectories (cf.~the discussion of boundary conditions  in \cref{sec:diffMaps}).

In the idealized setting where $\sum_{j\in  \mathcal{I}_k} \mathbf{Q}_\epsilon(i,j) = 1$ for all $i \in \mathcal{I}_k$, the restriction $\mathbf{Q}_\epsilon(\mathcal{I}_k, \mathcal{I}_k)$ is a stochastic matrix and we find  $ P_\text{exit}(\mathcal{I}_k)= 0$. For the spectral clustering method described in the previous subsection, we expect to obtain $K$ sets with relatively high coherence and one residual set with a lower coherence. We verify this for two case studies in~\cref{sec:exc}. %, in particular, Figures~\ref{fig:20160502_00_pexit},~\ref{fig:coherent_sets_20160504}~(b) and~\ref{fig:coherent_sets_20170126}~(b).
For comparison, for each coherent or residual set found, we also calculate $P_{\text{exit}}$ for 100 test sets and show their distribution as box-whiskers plots. Each of these test sets is generated by picking a random trajectory and selecting the $m$ closest points (with respect to the custom metric to be introduced in \cref{sec:dist}) in the initial distribution ($t=0$), where $m = |\mathcal{I}_k|$ is the number of points in the set to compare. Therefore, at $t=0$ the test sets resemble sets with minimal surfaces for a given volume (more specifically, intersections of balls with the initial distribution), which we consider a suitable basis for comparison. 

Another option to quantify coherence is to compute the largest eigenvalue of the restricted matrix $\mathbf{Q}_\epsilon(\mathcal{I}_k, \mathcal{I}_k)$, which determines the complement of the exit probability defined above under the stationary distribution of the respective set instead of a uniform distribution. Since $\mathbf{Q}_\epsilon$ is substochastic, the largest eigenvalue of the restricted matrix lies between $0$ and $1$, where a larger value corresponds to higher coherence. We provide this measure in the supplementary material.% as Figure~S5.

\subsection{Choosing $\epsilon$}
\label{sec:eps}
Recall the definition of the similarity matrix $\mathbf{K}_{t, \epsilon}\in \mathbb{R}^{m\times m}$ in \cref{eq:similarity_matrix} with the diffusion kernel introduced in \cref{eq:diffKernel}, 
where $\text{dist}(\cdot, \cdot)$ is a metric on $\mathbb{R}^n$.
Under the assumption that the points $x_t^i$ are distributed uniformly with respect to $\text{dist}(\cdot, \cdot)$, it is argued in Appendix A.2 of \textcite{koltaiDiffusionMapsEmbedding2020} and following \textcite{berryVariableBandwidthDiffusion2016, coifmanGraphLaplacianTomography2008} that $\epsilon>0$ should be chosen, if possible, such that the following approximation is valid:

% \begin{equation}
%     \begin{aligned}\label{eq:S_eps_heuristic}
%     S_t(\epsilon) :=  \hspace{1mm}&\sum_{i,j}\mathbf{K}_{t,\epsilon}(i,j)\\
%     \approx \hspace{1mm} & \sum_{i=1}^m C \int_{\mathbb{R}^{d(t)}} \exp \left(-\frac{\| x^i_t- y\|^2}{\epsilon} \right) \mathrm{d} y \\
%     =\hspace{1mm}& mC (\epsilon \pi)^{d(t)/2},
% \end{aligned}
% \end{equation}
% \ignorespacesafterend
\begin{equation}\label{eq:S_eps_heuristic}
\begin{aligned}
   S_t(\epsilon) := \hspace{1mm} & \sum_{i,j}\mathbf{K}_{t,\epsilon}(i,j)
     \\ 
    \approx \hspace{1mm} &\sum_{i=1}^m C \int_{\mathbb{R}^{d(t)}} \exp \left(-\frac{\| x^i_t- y\|^2}{\epsilon} \right) \mathrm{d} y \\
    =\hspace{1mm} & mC (\epsilon \pi)^{d(t)/2},
\end{aligned}
\end{equation}
\ignorespacesafterend
where $C>0$ is a constant that depends on how densely the points in $X_t$ populate $\mathbb{X}_t$ and $d(t)$ is the dimension of the manifold~$\mathbb{X}_t$. To better understand the constants $C$ and $d(t)$, assume that $X_t$ is a large $d$--dimensional grid of gridlength $\ell$ and consider the Euclidean distance $\text{dist}(x,y) = \|x-y\|$. Then, the sum $S_t(\epsilon)$ corresponds to a Riemannian integral approximation and the approximation in \cref{eq:S_eps_heuristic} is valid with $C$ being the average number of points per unit of volume, which is given by $C\approx \ell^{-d}$, respectively $\ell = C^{-1/d}$.

Taking the logarithm on both sides of \cref{eq:S_eps_heuristic} reveals an affine linear connection between $\log(S_t(\epsilon))$ and $\log(\epsilon)$:
\begin{equation}\label{eq:loglog_relation}
    \log(S_t(\epsilon)) \approx \hspace{1mm} \frac{d(t)}{2}\log(\epsilon) + \log(C) + \log(m) + \frac{d(t)}{2} \log(\pi).
\end{equation}
Hence, in order to determine a range of suitable values for $\epsilon$, we plot the function $S_{t}(\epsilon)$ versus $\epsilon$ in a log-log plot for each time $t$ and look for a range of $\epsilon$ in which the graph is linear. See~\cref{fig:eps_loglog} for an example. Additionally, we can read off the dimension $d(t)$, as well as a measure of density $\ell(t) = C^{-1/d(t)}$ of the point cloud $X_t$. 
\begin{align}
    d(t)  &:= 2 \cdot \max_{\epsilon > 0} \frac{\partial \log (S_t(\epsilon))}{\partial \log (\epsilon)}\label{eq:d_heuristic}\\
    \ell (t) &:=  C^{-1/d(t)} \label{eq:ell_heuristic} =  \left(\frac{S_t\epsilon^*}{m}\right)^{1/d(t)}(\epsilon^* \pi)^{1/2},
\end{align}
where $\epsilon^*>0$ is the value that maximizes the slope $\partial \log (S_t(\epsilon)) / \partial \log (\epsilon)$. We note that the derivations of $d(t)$ and $\ell(t)$ are not mathematically rigorous and are used heuristically. In particular, the dimension $d(t)$ does not have to be an integer and $\ell(t)$ is just an approximate measure of (inverse) density when the point cloud $X_t$ is not a perfect grid. We stress that, since $\ell(t)$ approximates a grid length, higher values correspond to lower point densities. In addition, we note that $d(t)$ is invariant under isotropic contraction/expansion of $X_t$ (it is scale-invariant), but $\ell(t)$ is not.

\subsection{Boundary handling with $\alpha$-shapes}
\label{sec:alpha_shapes}
The estimation of coherent sets requires proper handling of boundary points $\partial X_t \subset X_t$. Hence, a method is needed to determine which points lie on the boundary of a given point cloud $X_t$. This problem reduces to the well-researched problem of surface reconstruction from point cloud data. The simplest approach is to use the uniquely defined convex hull of $X_t$. This method is too coarse for our purpose, since the point cloud $X_t$ is in general not a convex object. Once concavity is permitted, detection of a bounding surface of a set of points is ambiguous and several algorithmic approaches exist \parencite{bergerSurveySurfaceReconstruction2017}. We have decided on using the established \texttt{alpha shape} algorithm first introduced by \textcite{edelsbrunnerShapeSetPoints1983} (cf.~ \textcite{edelsbrunnerAlphaShapesSurvey2012} for an overview), since it does not require surface normals and can be conveniently tuned by only one parameter~$\alpha \geq 0$. Large values of $\alpha$ correspond to a structured surface while small values of $\alpha$ result in a smooth surface. For a thorough derivation and details on algorithmic implementation, consult \textcite{edelsbrunnerThreedimensionalAlphaShapes1994}.

Let $X_t \subset \mathbb{R}^n$ be a finite set of points, $0 \leq \alpha < \infty$ a real number. We denote open balls in $\mathbb{R}^n$ of radius $\alpha$ by $b_{\alpha}$. An $\alpha$-ball $b_\alpha$ is said to be empty, if it does not contain any points from $X_t$. The $\alpha$-hull $\mathbb{H}_{\alpha}$ is then defined as the complement of the union of all empty $\alpha$-balls:
\begin{equation}
    \mathbb{H}_{\alpha} := \mathbb{R}^n \setminus \bigcup_{b_{\alpha} \cap X_t = \emptyset} b_{\alpha}.
\end{equation}
We define the boundary of $X_t$ to consist of those points that lie in the boundary of $\mathbb H_\alpha$, i.e.
\begin{equation*}
    \partial X_t := \{x \in X_t \mid x \in \partial \mathbb H_\alpha\}.
\end{equation*}
An equivalent definition of the boundary is that $x\in X_t$ lies in $\partial X_t$ if and only if there is an empty open $\alpha$-ball $b_\alpha$ such that $x\in \partial b_\alpha$. As $\alpha \rightarrow \infty$ the set $\mathbb{H}_\alpha$ recovers the convex hull, whereas $\alpha = 0$ results in $\mathbb H_\alpha = X_t$. Hence, the set $\partial X_t$ grows as $\alpha \to 0$, and for $\alpha$ small enough, we find $\partial X_t = X_t$.

This sparks the question of choosing $\alpha$ appropriately such that $\partial X_t$ defines a boundary of the point-cloud $X_t$ of the desired coarseness. 
As discussed in \cref{sec:eps}, $\sqrt{\epsilon^*}$ provides a measure of the typical distance between points in the point cloud. Therefore, it is natural to choose $\alpha$ in the same magnitude as $\sqrt{\epsilon^*}$.

The \texttt{alpha shape} algorithm assumes the points live in Euclidean space. However, in \cref{sec:exc} we apply our methods to atmospheric data. The atmosphere, being approximated by a spherical shell, is non-isotropic and globally non-Euclidean. Thus, constructing a hull in a Cartesian coordinate system, e.g. centered in Earth's core, is destined to fail as the large difference in scales between vertical and horizontal coordinates leads to points being sampled from a nearly two-dimensional region in space. In such a perspective, virtually all points would be boundary points. We have therefore decided to apply a stereographic projection centered at the North Pole with an undistorted latitude of $50^{\circ}$ N to the horizontal coordinates and applied a linear vertical scaling in accordance with the custom distance metric introduced in \cref{sec:dist} before applying the \texttt{alpha shape} algorithm. A stereographic projection seems apt since the air parcels of our examples stay on the Northern Hemisphere and are gathered around the mid-latitudes for most of the time. Other suitable coordinate transformations alter the selected boundary points only to a small degree and do not change the resulting coherent sets detected significantly (not shown). 

\section{Implementation}
\label{sec:imp}

All atmospheric fields used in the analysis are taken from the ERA5 reanalysis product provided by the European Centre for Medium-Range Weather Forecasts (ECMWF) \citep{hersbachERA5GlobalReanalysis2020}. It resolves the global atmosphere on a grid with a roughly 31 km horizontal spacing and 137 hybrid vertical levels between the surface and 1 hPa on hourly timescale. 

\subsection{Blocking identification}
\label{sec:block}

The atmospheric blocking regions are defined as in \citet{pfahlQuantifyingRelevanceAtmospheric2012}, who utilized the algorithm introduced by \citet{schwierzPerspicaciousIndicatorsAtmospheric2004}. More specifically, grid points are identified as blocked, if a vertically averaged (between $500$ hPa and $150$ hPa; the upper troposphere) negative PV anomaly (with respect to the monthly climatology) larger than 1.3 potential vorticity units ($10^{-6}$ K m\textsuperscript{2} kg\textsuperscript{-1} s\textsuperscript{-1}) (pvu) for at least five days is observed for a potentially traveling connected region (individual grid points need not experience this anomaly for five full days). Data are available in six-hourly time steps, and PV anomalies are required to have a spatial overlap of at least 70\% to be assigned to the same track. 

Though a host of different blocking identification mechanisms are available \citep{pinheiroAtmosphericBlockingIntercomparison2019}, this PV-based algorithm has been chosen since it encapsulates the most important dynamical features of atmospheric blocking \citep{schwierzPerspicaciousIndicatorsAtmospheric2004, croci-maspoliMultifacetedClimatologyAtmospheric2007} and directly identifies two-dimensional regions.  The identified regions will usually mark the areas responsible dynamically for the blocking characteristics (i.e.~the high-pressure ridge regions) rather than the areas marked by a geopotential height reversal. The focus of this study lies in the demonstration of the methodological framework when applied to atmospheric blocking air streams rather than in arriving at definitive or quantative insights about blocking consistent across different blocking definitions, which is why we abstain from comparing results between different blocking indices.

\subsection{Initial points}
\label{sec:startPoints}

The method for the identification of coherent air streams described in \cref{sec:the} is applied to two case studies. Given the two--dimensional, global, Boolean field of whether a grid point is blocked or not, for each case, an atmospheric blocking event is identified as a connected region of \texttt{True} values developing in time. For an individual time step, a respective region is ``filled'' with trajectory initial points with a vertical distance of $7$ hPa between $550$ and $150$ hPa (we choose $550$ hPa instead of $500$ hPa for a slightly broader scope; the same does not apply for the upper limit, since it would likely cross the tropopause) and a horizontal distance given by the scale difference parameter $\kappa$ times the vertical distance (cf.~\cref{sec:dist}). In our case study, for a scaling parameter of $\kappa = 15$ km hPa\textsuperscript{-1}, a horizontal distance of $105$ km was used. Such a point density has emerged as the highest possible point density that still allowed for an acceptable computational complexity. A zero-mean Gaussian noise with standard deviation equal to a quarter of the distance in the respective direction is then added to each point individually to prevent the regular structure of the initial point distribution to bias the coherent set clustering later on. Finally, all initial points that lie above the dynamic tropopause -- defined as the 2 pvu isosurface -- are removed.  

\subsection{Trajectory calculation}
\label{sec:traj}
The initial points are then used to calculate three-day forward and backward trajectories from three-dimensional wind fields on model levels using the LAGRangian ANalysis TOol (\texttt{LAGRANTO}) \citep{sprengerLAGRANTOLagrangianAnalysis2015}, which employs an iterative predictor-corrector procedure. We think of the resulting trajectories as solutions of the dynamical system describing the motion of air parcels in the atmosphere ($x_t^i$ from \cref{sec:the}). Various dynamical variables can be traced along the path of the air parcels' trajectories including potential temperature $\theta$, specific humidity $q$, temperature $T$ and all coordinates and velocities. These will reveal the dynamical properties present in the clusters generated from purely geometric information.

\subsection{Distance Calculation}
\label{sec:dist}
Our methodology presented in \cref{sec:the} is based on point-wise distance calculation. Here, again, the issue of vastly different length scales in the horizontal and vertical directions arises. Resorting to a map projection as with the \texttt{alpha shapes} algorithm described in \cref{sec:alpha_shapes} does, however, not seem to be the best option since errors introduced during the stereographic projection can be avoided. This is because calculating distances between points does not necessarily require the points to live in Euclidean space. In contrast to \citet{banischUnderstandingGeometryTransport2017}, who relied on the Euclidean norm as a measure of distance, we therefore construct a non--Euclidean distance which connects the vertical and horizontal scales through a scale parameter $\kappa$:

\begin{equation}
   \kappa = \frac{\overline{\sqrt{u^2 + v^2}}}{\overline{\vert\omega\vert}}  = \frac{\sum_{i=1}^m \sum_{t=0}^T \sqrt{(u^i_t)^2 + (v^i_t)^2}}{\sum_{i=1}^m \sum_{t=0}^T \vert \omega^i_t\vert},\label{eq:k}
\end{equation}
where $u^i_t,v^i_t$ are the two horizontal and $\omega^i_t$ the vertical velocity component of the $i$-th air parcel at time $t$. For two points $x^i = (\varphi^i,\lambda^i,p^i)$ and $x^j = (\varphi^j,\lambda^j,p^j)$, given by their respective latitudes $\varphi$, longitudes $\lambda$, and pressure level $p$, we then define
\begin{align*}
        \text{dist} (x^i, x^j) & = \sqrt{\text{dist}_\mathrm{h}(x^i, x^j)^2 + (\kappa(p^j - p^i))^2}, \\
        \text{dist}_\mathrm{h}(x^i, x^j) & = 2r_{\mathrm{E}} \arcsin\left(\sqrt{\sin^2\left(\frac{\varphi^j - \varphi^i}{2}\right) + \cos \varphi^i \cdot \cos \varphi^j \cdot \sin^2\left(\frac{\lambda^j - \lambda^i}{2}\right)}\right), 
\end{align*}
where $r_{\mathrm{E}}$ stands for Earth's radius. 
The distance is symmetric and positive. The horizontal distance $\text{dist}_\mathrm{h}$ is the Haversine distance which approximates the great-circle distance of two points on Earth's surface (assuming a spherical shape) well \citep{greenSphericalTrigonometry1977}. 

For the scale parameter $\kappa$, a heuristic approach has been chosen that estimates the difference in scales by comparing average horizontal and vertical velocities, where the average is taken over all trajectories and time steps. We think of distances to be similar if air parcels take roughly the same amount of time to overcome them given some average velocity which is the reasoning behind the construction of $\kappa$. In addition, atmospheric turbulence -- the dominant source of diffusion at the scales investigated here -- roughly scales with velocity. The developed notion of distance relies only on geometric information (if one conceives velocities as geometric), which allows comparison of purely geometric coherence to similarity of dynamic properties. For the construction of $\kappa$ we have deliberately abstained from including measures of vertical stability or asymptotic methods since the phenomena investigated feature relevant processes on synoptic as well as mesoscale which would further complicate the choice of scale-connecting characteristic quantities \citep{kleinScaleDependentModelsAtmospheric2010}. Note that, due to definition of $\kappa$ in \cref{eq:k}, the custom metric $\text{dist}(\cdot, \cdot)$ is formally measured in kilometers.

We remark that estimated values of $\kappa$ varied only by roughly 20 \% and results were rather insensitive to the exact value of $\kappa$ applied in both the algorithm and the initial point generation. For ease of computation and comparability between cases, we have therefore decided to choose a constant $\kappa = 15$ km hPa\textsuperscript{-1} across all cases investigated. Note that requiring exact equality between the empirical $\kappa$ and the $\kappa$ used in the initial point generation would require extensive iteration, since the empirical $\kappa$ depends on the trajectories, which, in turn, depend on the initial point locations.

